{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcea429",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de598530",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "619c4e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: [{'generated_text': 'Translate the following English text to French: \\'Hello, how are you?\\' It looks like a short speech given to Charles Hindenburg in which he says, \"My friend, you don\\'t know me, but I know you.\"\\' Whoever tells you that, is a liar. Whatever the true position of speaking in the Empire is, someone will find it a __________- value fact.\"'}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "api_key = API_KEY\n",
    "headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "\n",
    "# Define the model to use and your input text\n",
    "model_name = \"gpt2\"  \n",
    "api_url = f\"https://api-inference.huggingface.co/models/{model_name}\"\n",
    "data = {\"inputs\": \"Translate the following English text to French: 'Hello, how are you?'\"}\n",
    "\n",
    "# Make the API call\n",
    "response = requests.post(api_url, headers=headers, json=data)\n",
    "\n",
    "# Check and display the response\n",
    "if response.status_code == 200:\n",
    "    print(\"Response:\", response.json())\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c18db3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"inputs\": \"Answer the question in brief: 'Was Mahatma Gandhi a good person?'\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd3c7a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: [{'generated_text': \"Answer the question in brief: 'Was Mahatma Gandhi a good person?' And he answered them he was a good man.' In two years, his support rose to seven million dollars and the Congress jumped to $99. Of all Indians, Gandhi's programme was the only one that came close to winning.\\n\\nWhat might have surprised these journalists and academics, Gandhi's followers contend, was not his conservative conservative support (he voted against restraint on the working-class reforms opposed by the Working People's Party) nor his free market liberalism (VfS), but his fatal\"}]\n"
     ]
    }
   ],
   "source": [
    "# Make the API call\n",
    "response = requests.post(api_url, headers=headers, json=data)\n",
    "\n",
    "# Check and display the response\n",
    "if response.status_code == 200:\n",
    "    print(\"Response:\", response.json())\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "420e6b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: arxiv in c:\\users\\sruti baibhab mishra\\anaconda3\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: requests~=2.32.0 in c:\\users\\sruti baibhab mishra\\anaconda3\\lib\\site-packages (from arxiv) (2.32.3)\n",
      "Requirement already satisfied: feedparser~=6.0.10 in c:\\users\\sruti baibhab mishra\\anaconda3\\lib\\site-packages (from arxiv) (6.0.11)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\sruti baibhab mishra\\anaconda3\\lib\\site-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sruti baibhab mishra\\anaconda3\\lib\\site-packages (from requests~=2.32.0->arxiv) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sruti baibhab mishra\\anaconda3\\lib\\site-packages (from requests~=2.32.0->arxiv) (2.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sruti baibhab mishra\\anaconda3\\lib\\site-packages (from requests~=2.32.0->arxiv) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sruti baibhab mishra\\anaconda3\\lib\\site-packages (from requests~=2.32.0->arxiv) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "307cda9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: arxiv\n",
      "Version: 2.1.3\n",
      "Summary: Python wrapper for the arXiv API: https://arxiv.org/help/api/\n",
      "Home-page: https://github.com/lukasschwab/arxiv.py\n",
      "Author: Lukas Schwab\n",
      "Author-email: lukas.schwab@gmail.com\n",
      "License: MIT\n",
      "Location: c:\\users\\sruti baibhab mishra\\anaconda3\\lib\\site-packages\n",
      "Requires: requests, feedparser\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3ea69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f11cc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install arxiv --upgrade --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "069778c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CFD analysis of Osteochondral in-vitro modelsYes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Local\\Temp\\ipykernel_28244\\274157934.py:16: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for result in search.results():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A model-independent reconstruction of the matter power spectrum\n",
      "Published: 2024-11-11 15:58:24+00:00\n",
      "Summary: We propose a new model-independent reconstruction method for the matter power\n",
      "spectrum based on its time dependence and a combination of observations from\n",
      "different redshifts. The method builds on a perturbative expansion in terms of\n",
      "the linear growth function, with each coefficient in the expansion being a free\n",
      "function of scale, to be reconstructed from the data. When using the linear\n",
      "growth function of a specific cosmological model, e.g. $\\Lambda$CDM, the\n",
      "reconstruction can serve as a consistency check for non-linear modeling in that\n",
      "given model, as well as a new method for detecting departures from the assumed\n",
      "model in the data. As an application, we show how using DES Y3 3x2pt and Planck\n",
      "PR4 CMB lensing data, assuming a $\\Lambda$CDM linear growth and first order\n",
      "expansion, the reconstructed matter power spectrum $P_{\\rm m}(k)$ is compatible\n",
      "with that computed from $\\Lambda$CDM and halo model. In particular, we show\n",
      "that the method reconstructs the non-linear part of $P_{\\rm m}(k)$ for\n",
      "$k\\gtrsim 1\\ \\rm{Mpc}^{-1}$ without the need of assuming a non-linear model.\n",
      "PDF URL: http://arxiv.org/pdf/2411.07082v1 \n",
      "\n",
      "Title: Quantum Homotopy Analysis Method with Secondary Linearization for Nonlinear Partial Differential Equations\n",
      "Published: 2024-11-11 07:25:38+00:00\n",
      "Summary: Nonlinear partial differential equations (PDEs) are crucial for modeling\n",
      "complex fluid dynamics and are foundational to many computational fluid\n",
      "dynamics (CFD) applications. However, solving these nonlinear PDEs is\n",
      "challenging due to the vast computational resources they demand, highlighting\n",
      "the pressing need for more efficient computational methods. Quantum computing\n",
      "offers a promising but technically challenging approach to solving nonlinear\n",
      "PDEs. Recently, Liao proposed a framework that leverages quantum computing to\n",
      "accelerate the solution of nonlinear PDEs based on the homotopy analysis method\n",
      "(HAM), a semi-analytical technique that transforms nonlinear PDEs into a series\n",
      "of linear PDEs. However, the no-cloning theorem in quantum computing poses a\n",
      "major limitation, where directly applying quantum simulation to each HAM step\n",
      "results in exponential complexity growth with the HAM truncation order. This\n",
      "study introduces a \"secondary linearization\" approach that maps the whole HAM\n",
      "process into a system of linear PDEs, allowing for a one-time solution using\n",
      "established quantum PDE solvers. Our method preserves the exponential speedup\n",
      "of quantum linear PDE solvers while ensuring that computational complexity\n",
      "increases only polynomially with the HAM truncation order. We demonstrate the\n",
      "efficacy of our approach by applying it to the Burgers' equation and the\n",
      "Korteweg-de Vries (KdV) equation. Our approach provides a novel pathway for\n",
      "transforming nonlinear PDEs into linear PDEs, with potential applications to\n",
      "fluid dynamics. This work thus lays the foundation for developing quantum\n",
      "algorithms capable of solving the Navier-Stokes equations, ultimately offering\n",
      "a promising route to accelerate their solutions using quantum computing.\n",
      "PDF URL: http://arxiv.org/pdf/2411.06759v1 \n",
      "\n",
      "Title: An Overview on IRS-Enabled Sensing and Communications for 6G: Architectures, Fundamental Limits, and Joint Beamforming Designs\n",
      "Published: 2024-11-11 03:09:12+00:00\n",
      "Summary: This paper presents an overview on intelligent reflecting surface\n",
      "(IRS)-enabled sensing and communication for the forthcoming sixth-generation\n",
      "(6G) wireless networks, in which IRSs are strategically deployed to proactively\n",
      "reconfigure wireless environments to improve both sensing and communication\n",
      "(S&C) performance. First, we exploit a single IRS to enable wireless sensing in\n",
      "the base station's (BS's) non-line-of-sight (NLoS) area. In particular, we\n",
      "present three IRS-enabled NLoS target sensing architectures with fully-passive,\n",
      "semi-passive, and active IRSs, respectively. We compare their pros and cons by\n",
      "analyzing the fundamental sensing performance limits for target detection and\n",
      "parameter estimation. Next, we consider a single IRS to facilitate integrated\n",
      "sensing and communication (ISAC), in which the transmit signals at the BS are\n",
      "used for achieving both S&C functionalities, aided by the IRS through\n",
      "reflective beamforming. We present joint transmit signal and receiver\n",
      "processing designs for realizing efficient ISAC, and jointly optimize the\n",
      "transmit beamforming at the BS and reflective beamforming at the IRS to balance\n",
      "the fundamental performance tradeoff between S&C. Furthermore, we discuss\n",
      "multi-IRS networked ISAC, by particularly focusing on multi-IRS-enabled\n",
      "multi-link ISAC, multi-region ISAC, and ISAC signal routing, respectively.\n",
      "Finally, we highlight various promising research topics in this area to\n",
      "motivate future work.\n",
      "PDF URL: http://arxiv.org/pdf/2411.06687v1 \n",
      "\n",
      "Title: Inductive Graph Few-shot Class Incremental Learning\n",
      "Published: 2024-11-11 00:06:20+00:00\n",
      "Summary: Node classification with Graph Neural Networks (GNN) under a fixed set of\n",
      "labels is well known in contrast to Graph Few-Shot Class Incremental Learning\n",
      "(GFSCIL), which involves learning a GNN classifier as graph nodes and classes\n",
      "growing over time sporadically. We introduce inductive GFSCIL that continually\n",
      "learns novel classes with newly emerging nodes while maintaining performance on\n",
      "old classes without accessing previous data. This addresses the practical\n",
      "concern of transductive GFSCIL, which requires storing the entire graph with\n",
      "historical data. Compared to the transductive GFSCIL, the inductive setting\n",
      "exacerbates catastrophic forgetting due to inaccessible previous data during\n",
      "incremental training, in addition to overfitting issue caused by label\n",
      "sparsity. Thus, we propose a novel method, called Topology-based class\n",
      "Augmentation and Prototype calibration (TAP). To be specific, it first creates\n",
      "a triple-branch multi-topology class augmentation method to enhance model\n",
      "generalization ability. As each incremental session receives a disjoint\n",
      "subgraph with nodes of novel classes, the multi-topology class augmentation\n",
      "method helps replicate such a setting in the base session to boost backbone\n",
      "versatility. In incremental learning, given the limited number of novel class\n",
      "samples, we propose an iterative prototype calibration to improve the\n",
      "separation of class prototypes. Furthermore, as backbone fine-tuning poses the\n",
      "feature distribution drift, prototypes of old classes start failing over time,\n",
      "we propose the prototype shift method for old classes to compensate for the\n",
      "drift. We showcase the proposed method on four datasets.\n",
      "PDF URL: http://arxiv.org/pdf/2411.06634v1 \n",
      "\n",
      "Title: Brillouin photonics engine in the thin-film lithium niobate platform\n",
      "Published: 2024-11-10 21:19:58+00:00\n",
      "Summary: Stimulated Brillouin scattering (SBS) is revolutionizing low-noise lasers and\n",
      "microwave photonic systems. However, despite extensive explorations of a\n",
      "low-loss and versatile integrated platform for Brillouin photonic circuits,\n",
      "current options fall short due to limited technological scalability or\n",
      "inadequate SBS gain. Here we introduce the thin-film lithium niobate (TFLN)\n",
      "platform as the go-to choice for integrated Brillouin photonics applications.\n",
      "We report the angle-dependent strong SBS gain in this platform, which can\n",
      "overcome the intrinsic propagation loss. Furthermore, we demonstrate the first\n",
      "stimulated Brillouin laser in TFLN with a tuning range > 20 nm and utilize it\n",
      "to achieve high-purity RF signal generation with an intrinsic linewidth of 9\n",
      "Hz. Finally, we devise a high-rejection Brillouin-based microwave photonic\n",
      "notch filter, for the first time, integrating an SBS spiral, an on-chip\n",
      "modulator, and a tunable ring all within the same platform. This TFLN-based\n",
      "Brillouin photonics engine uniquely combines the scalability of this platform\n",
      "and the versatility of SBS. Moreover, it bridges SBS with other functionalities\n",
      "in the TFLN platform, unlocking new possibilities for Brillouin-based\n",
      "applications with unparalleled performances.\n",
      "PDF URL: http://arxiv.org/pdf/2411.06599v1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "from datetime import datetime\n",
    "\n",
    "# Accept user input for research topic\n",
    "topic = input(\"CFD analysis of Osteochondral in-vitro models\")\n",
    "start_date = \"2019-01-01\"  # Define the start date for the 5-year period\n",
    "\n",
    "# Search Arxiv for papers on the topic within the last five years\n",
    "search = arxiv.Search(\n",
    "    query=topic,\n",
    "    max_results=5,  # Adjust as needed\n",
    "    sort_by=arxiv.SortCriterion.SubmittedDate\n",
    ")\n",
    "\n",
    "# Display fetched papers\n",
    "for result in search.results():\n",
    "    print(\"Title:\", result.title)\n",
    "    print(\"Published:\", result.published)\n",
    "    print(\"Summary:\", result.summary)\n",
    "    print(\"PDF URL:\", result.pdf_url, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb271d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Stimulated Brillouin scattering (SBS) is revolutionizing low-noise lasers and microwave photonic systems. Current options fall short due to limited technological scalability or inadequate SBS gain. We introduce the thin-film lithium niobate (TFLN) platform as the go-to choice.\n",
      "Answer to Question: Brillouin photonic circuits\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Set up your API key\n",
    "api_key = API_KEY\n",
    "headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "\n",
    "# Define models for summarization and Q&A\n",
    "summarization_model = \"facebook/bart-large-cnn\"\n",
    "qa_model = \"deepset/roberta-base-squad2\"\n",
    "\n",
    "# Function for Summarization\n",
    "def summarize_text(text):\n",
    "    api_url = f\"https://api-inference.huggingface.co/models/{summarization_model}\"\n",
    "    data = {\"inputs\": text}\n",
    "    response = requests.post(api_url, headers=headers, json=data)\n",
    "    return response.json()[0][\"summary_text\"] if response.status_code == 200 else response.text\n",
    "\n",
    "# Function for Question Answering\n",
    "def answer_question(context, question):\n",
    "    api_url = f\"https://api-inference.huggingface.co/models/{qa_model}\"\n",
    "    data = {\"inputs\": {\"question\": question, \"context\": context}}\n",
    "    response = requests.post(api_url, headers=headers, json=data)\n",
    "    return response.json()[\"answer\"] if response.status_code == 200 else response.text\n",
    "\n",
    "# Test Data\n",
    "paper_summary = \"\"\"\n",
    "    Stimulated Brillouin scattering (SBS) is revolutionizing low-noise lasers and\n",
    "microwave photonic systems. However, despite extensive explorations of a\n",
    "low-loss and versatile integrated platform for Brillouin photonic circuits,\n",
    "current options fall short due to limited technological scalability or\n",
    "inadequate SBS gain. Here we introduce the thin-film lithium niobate (TFLN)\n",
    "platform as the go-to choice for integrated Brillouin photonics applications.\n",
    "We report the angle-dependent strong SBS gain in this platform, which can\n",
    "overcome the intrinsic propagation loss. Furthermore, we demonstrate the first\n",
    "stimulated Brillouin laser in TFLN with a tuning range > 20 nm and utilize it\n",
    "to achieve high-purity RF signal generation with an intrinsic linewidth of 9\n",
    "Hz. Finally, we devise a high-rejection Brillouin-based microwave photonic\n",
    "notch filter, for the first time, integrating an SBS spiral, an on-chip\n",
    "modulator, and a tunable ring all within the same platform. This TFLN-based\n",
    "Brillouin photonics engine uniquely combines the scalability of this platform\n",
    "and the versatility of SBS. Moreover, it bridges SBS with other functionalities\n",
    "in the TFLN platform, unlocking new possibilities for Brillouin-based\n",
    "applications with unparalleled performances.\n",
    "\"\"\"\n",
    "question = \"What type of circuits are discussed?\"\n",
    "\n",
    "# Example Usage\n",
    "print(\"Summary:\", summarize_text(paper_summary))\n",
    "print(\"Answer to Question:\", answer_question(paper_summary, question))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5827efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting influxdb\n",
      "  Downloading influxdb-5.3.2-py2.py3-none-any.whl (79 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\sruti baibhab mishra\\anaconda3\\lib\\site-packages (from influxdb) (1.16.0)\n",
      "Requirement already satisfied: pytz in c:\\users\\sruti baibhab mishra\\anaconda3\\lib\\site-packages (from influxdb) (2024.1)\n",
      "Requirement already satisfied: msgpack in c:\\users\\sruti baibhab mishra\\anaconda3\\lib\\site-packages (from influxdb) (1.0.2)\n",
      "Requirement already satisfied: requests>=2.17.0 in c:\\users\\sruti baibhab mishra\\anaconda3\\lib\\site-packages (from influxdb) (2.32.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.0 in c:\\users\\sruti baibhab mishra\\anaconda3\\lib\\site-packages (from influxdb) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sruti baibhab mishra\\anaconda3\\lib\\site-packages (from requests>=2.17.0->influxdb) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sruti baibhab mishra\\anaconda3\\lib\\site-packages (from requests>=2.17.0->influxdb) (2.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sruti baibhab mishra\\anaconda3\\lib\\site-packages (from requests>=2.17.0->influxdb) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sruti baibhab mishra\\anaconda3\\lib\\site-packages (from requests>=2.17.0->influxdb) (2024.7.4)\n",
      "Installing collected packages: influxdb\n",
      "Successfully installed influxdb-5.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install influxdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c8add3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting elasticsearch\n",
      "  Downloading elasticsearch-8.15.1-py3-none-any.whl (524 kB)\n",
      "Collecting elastic-transport<9,>=8.13\n",
      "  Downloading elastic_transport-8.15.1-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\sruti baibhab mishra\\anaconda3\\lib\\site-packages (from elastic-transport<9,>=8.13->elasticsearch) (2024.7.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in c:\\users\\sruti baibhab mishra\\anaconda3\\lib\\site-packages (from elastic-transport<9,>=8.13->elasticsearch) (2.2.2)\n",
      "Installing collected packages: elastic-transport, elasticsearch\n",
      "Successfully installed elastic-transport-8.15.1 elasticsearch-8.15.1\n"
     ]
    }
   ],
   "source": [
    "!pip install elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af577554",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Program Files\\Python311\\Lib\\runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Local\\Temp\\ipykernel_28244\\3871571595.py\", line 2, in <module>\n",
      "    from transformers import pipeline\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\import_utils.py\", line 1136, in __getattr__\n",
      "    module = self._get_module(self._class_to_module[name])\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\import_utils.py\", line 1146, in _get_module\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\__init__.py\", line 44, in <module>\n",
      "    from .audio_classification import AudioClassificationPipeline\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\audio_classification.py\", line 21, in <module>\n",
      "    from .base import PIPELINE_INIT_ARGS, Pipeline\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\base.py\", line 36, in <module>\n",
      "    from ..modelcard import ModelCard\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\modelcard.py\", line 48, in <module>\n",
      "    from .training_args import ParallelMode\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\training_args.py\", line 30, in <module>\n",
      "    from .trainer_utils import (\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\trainer_utils.py\", line 47, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\__init__.py\", line 47, in <module>\n",
      "    from tensorflow._api.v2 import __internal__\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.__internal__ import autograph\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\_api\\v2\\__internal__\\autograph\\__init__.py\", line 8, in <module>\n",
      "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\autograph\\core\\ag_ctx.py\", line 21, in <module>\n",
      "    from tensorflow.python.autograph.utils import ag_logging\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\autograph\\utils\\__init__.py\", line 17, in <module>\n",
      "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\autograph\\utils\\context_managers.py\", line 19, in <module>\n",
      "    from tensorflow.python.framework import ops\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 46, in <module>\n",
      "    from tensorflow.python import pywrap_tfe\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\pywrap_tfe.py\", line 25, in <module>\n",
      "    from tensorflow.python._pywrap_tfe import *\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;31mAttributeError\u001B[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Program Files\\Python311\\Lib\\runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Local\\Temp\\ipykernel_28244\\3871571595.py\", line 2, in <module>\n",
      "    from transformers import pipeline\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\import_utils.py\", line 1136, in __getattr__\n",
      "    module = self._get_module(self._class_to_module[name])\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\import_utils.py\", line 1146, in _get_module\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\__init__.py\", line 44, in <module>\n",
      "    from .audio_classification import AudioClassificationPipeline\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\audio_classification.py\", line 21, in <module>\n",
      "    from .base import PIPELINE_INIT_ARGS, Pipeline\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\base.py\", line 36, in <module>\n",
      "    from ..modelcard import ModelCard\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\modelcard.py\", line 48, in <module>\n",
      "    from .training_args import ParallelMode\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\training_args.py\", line 30, in <module>\n",
      "    from .trainer_utils import (\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\trainer_utils.py\", line 47, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\__init__.py\", line 47, in <module>\n",
      "    from tensorflow._api.v2 import __internal__\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.__internal__ import autograph\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\_api\\v2\\__internal__\\autograph\\__init__.py\", line 8, in <module>\n",
      "    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\autograph\\core\\ag_ctx.py\", line 21, in <module>\n",
      "    from tensorflow.python.autograph.utils import ag_logging\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\autograph\\utils\\__init__.py\", line 17, in <module>\n",
      "    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\autograph\\utils\\context_managers.py\", line 19, in <module>\n",
      "    from tensorflow.python.framework import ops\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 49, in <module>\n",
      "    from tensorflow.python.client import pywrap_tf_session\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\client\\pywrap_tf_session.py\", line 19, in <module>\n",
      "    from tensorflow.python.client._pywrap_tf_session import *\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;31mAttributeError\u001B[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Program Files\\Python311\\Lib\\runpy.py\", line 198, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\runpy.py\", line 88, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Local\\Temp\\ipykernel_28244\\3871571595.py\", line 2, in <module>\n",
      "    from transformers import pipeline\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\import_utils.py\", line 1136, in __getattr__\n",
      "    module = self._get_module(self._class_to_module[name])\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\import_utils.py\", line 1146, in _get_module\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"C:\\Program Files\\Python311\\Lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\__init__.py\", line 44, in <module>\n",
      "    from .audio_classification import AudioClassificationPipeline\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\audio_classification.py\", line 21, in <module>\n",
      "    from .base import PIPELINE_INIT_ARGS, Pipeline\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\base.py\", line 36, in <module>\n",
      "    from ..modelcard import ModelCard\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\modelcard.py\", line 48, in <module>\n",
      "    from .training_args import ParallelMode\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\training_args.py\", line 30, in <module>\n",
      "    from .trainer_utils import (\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\trainer_utils.py\", line 47, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\__init__.py\", line 47, in <module>\n",
      "    from tensorflow._api.v2 import __internal__\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py\", line 11, in <module>\n",
      "    from tensorflow._api.v2.__internal__ import distribute\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\_api\\v2\\__internal__\\distribute\\__init__.py\", line 8, in <module>\n",
      "    from tensorflow._api.v2.__internal__.distribute import combinations\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\_api\\v2\\__internal__\\distribute\\combinations\\__init__.py\", line 8, in <module>\n",
      "    from tensorflow.python.distribute.combinations import env # line: 456\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\distribute\\combinations.py\", line 33, in <module>\n",
      "    from tensorflow.python.distribute import collective_all_reduce_strategy\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\distribute\\collective_all_reduce_strategy.py\", line 25, in <module>\n",
      "    from tensorflow.python.distribute import cross_device_ops as cross_device_ops_lib\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\distribute\\cross_device_ops.py\", line 28, in <module>\n",
      "    from tensorflow.python.distribute import cross_device_utils\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\distribute\\cross_device_utils.py\", line 22, in <module>\n",
      "    from tensorflow.python.distribute import values as value_lib\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\distribute\\values.py\", line 23, in <module>\n",
      "    from tensorflow.python.distribute import distribute_lib\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\", line 205, in <module>\n",
      "    from tensorflow.python.data.ops import dataset_ops\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\data\\__init__.py\", line 21, in <module>\n",
      "    from tensorflow.python.data import experimental\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py\", line 98, in <module>\n",
      "    from tensorflow.python.data.experimental import service\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py\", line 419, in <module>\n",
      "    from tensorflow.python.data.experimental.ops.data_service_ops import distribute\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py\", line 26, in <module>\n",
      "    from tensorflow.python.data.ops import dataset_ops\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 34, in <module>\n",
      "    from tensorflow.python.data.ops import iterator_ops\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 45, in <module>\n",
      "    from tensorflow.python.training.saver import BaseSaverBuilder\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\training\\saver.py\", line 50, in <module>\n",
      "    from tensorflow.python.training import py_checkpoint_reader\n",
      "  File \"C:\\Users\\SRUTI BAIBHAB MISHRA\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py\", line 19, in <module>\n",
      "    from tensorflow.python.util._pywrap_checkpoint_reader import CheckpointReader\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;31mAttributeError\u001B[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.pipelines because of the following error (look up to see its traceback):\ninitialization of _pywrap_checkpoint_reader raised unreported exception",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mSystemError\u001B[0m                               Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\import_utils.py:1146\u001B[0m, in \u001B[0;36m_LazyModule._get_module\u001B[1;34m(self, module_name)\u001B[0m\n\u001B[0;32m   1145\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1146\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmodule_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__name__\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1147\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32mC:\\Program Files\\Python311\\Lib\\importlib\\__init__.py:126\u001B[0m, in \u001B[0;36mimport_module\u001B[1;34m(name, package)\u001B[0m\n\u001B[0;32m    125\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1206\u001B[0m, in \u001B[0;36m_gcd_import\u001B[1;34m(name, package, level)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1178\u001B[0m, in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1149\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:690\u001B[0m, in \u001B[0;36m_load_unlocked\u001B[1;34m(spec)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:940\u001B[0m, in \u001B[0;36mexec_module\u001B[1;34m(self, module)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:241\u001B[0m, in \u001B[0;36m_call_with_frames_removed\u001B[1;34m(f, *args, **kwds)\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\__init__.py:44\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     36\u001B[0m     HUGGINGFACE_CO_RESOLVE_ENDPOINT,\n\u001B[0;32m     37\u001B[0m     is_kenlm_available,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     42\u001B[0m     logging,\n\u001B[0;32m     43\u001B[0m )\n\u001B[1;32m---> 44\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01maudio_classification\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AudioClassificationPipeline\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautomatic_speech_recognition\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutomaticSpeechRecognitionPipeline\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\audio_classification.py:21\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m add_end_docstrings, is_torch_available, logging\n\u001B[1;32m---> 21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m PIPELINE_INIT_ARGS, Pipeline\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_torch_available():\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\base.py:36\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimage_processing_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BaseImageProcessor\n\u001B[1;32m---> 36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodelcard\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ModelCard\n\u001B[0;32m     37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mauto\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconfiguration_auto\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AutoConfig\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\modelcard.py:48\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mauto\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodeling_auto\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     33\u001B[0m     MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING_NAMES,\n\u001B[0;32m     34\u001B[0m     MODEL_FOR_CAUSAL_LM_MAPPING_NAMES,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     46\u001B[0m     MODEL_FOR_ZERO_SHOT_IMAGE_CLASSIFICATION_MAPPING_NAMES,\n\u001B[0;32m     47\u001B[0m )\n\u001B[1;32m---> 48\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtraining_args\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ParallelMode\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     50\u001B[0m     MODEL_CARD_NAME,\n\u001B[0;32m     51\u001B[0m     cached_file,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     57\u001B[0m     logging,\n\u001B[0;32m     58\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\training_args.py:30\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdebug_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DebugOption\n\u001B[1;32m---> 30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtrainer_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     31\u001B[0m     EvaluationStrategy,\n\u001B[0;32m     32\u001B[0m     FSDPOption,\n\u001B[0;32m     33\u001B[0m     HubStrategy,\n\u001B[0;32m     34\u001B[0m     IntervalStrategy,\n\u001B[0;32m     35\u001B[0m     SchedulerType,\n\u001B[0;32m     36\u001B[0m     ShardedDDPOption,\n\u001B[0;32m     37\u001B[0m )\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     39\u001B[0m     ExplicitEnum,\n\u001B[0;32m     40\u001B[0m     cached_property,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     55\u001B[0m     requires_backends,\n\u001B[0;32m     56\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\trainer_utils.py:47\u001B[0m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_tf_available():\n\u001B[1;32m---> 47\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mseed_worker\u001B[39m(_):\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\__init__.py:47\u001B[0m\n\u001B[0;32m     45\u001B[0m _tf2\u001B[38;5;241m.\u001B[39menable()\n\u001B[1;32m---> 47\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __internal__\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __operators__\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:11\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m__internal__\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dispatch\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m__internal__\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m distribute\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m__internal__\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m eager_context\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\_api\\v2\\__internal__\\distribute\\__init__.py:8\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_sys\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m__internal__\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistribute\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m combinations\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_api\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mv2\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m__internal__\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistribute\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m interim\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\_api\\v2\\__internal__\\distribute\\combinations\\__init__.py:8\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_sys\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistribute\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcombinations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m env \u001B[38;5;66;03m# line: 456\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistribute\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcombinations\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m generate \u001B[38;5;66;03m# line: 365\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\distribute\\combinations.py:33\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mclient\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m session\n\u001B[1;32m---> 33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistribute\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m collective_all_reduce_strategy\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistribute\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m distribute_lib\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\distribute\\collective_all_reduce_strategy.py:25\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistribute\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m collective_util\n\u001B[1;32m---> 25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistribute\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cross_device_ops \u001B[38;5;28;01mas\u001B[39;00m cross_device_ops_lib\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistribute\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cross_device_utils\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\distribute\\cross_device_ops.py:28\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistribute\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m collective_util\n\u001B[1;32m---> 28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistribute\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cross_device_utils\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistribute\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m device_util\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\distribute\\cross_device_utils.py:22\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistribute\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m collective_util\n\u001B[1;32m---> 22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistribute\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m values \u001B[38;5;28;01mas\u001B[39;00m value_lib\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backprop_util\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\distribute\\values.py:23\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistribute\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m device_util\n\u001B[1;32m---> 23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistribute\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m distribute_lib\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistribute\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m packed_distributed_variable \u001B[38;5;28;01mas\u001B[39;00m packed\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:205\u001B[0m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautograph\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimpl\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m api \u001B[38;5;28;01mas\u001B[39;00m autograph\n\u001B[1;32m--> 205\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dataset_ops\n\u001B[0;32m    206\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdistribute\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m collective_util\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\data\\__init__.py:21\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# pylint: disable=unused-import\u001B[39;00m\n\u001B[1;32m---> 21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m experimental\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdataset_ops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AUTOTUNE\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py:98\u001B[0m\n\u001B[0;32m     97\u001B[0m \u001B[38;5;66;03m# pylint: disable=unused-import\u001B[39;00m\n\u001B[1;32m---> 98\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m service\n\u001B[0;32m     99\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbatching\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dense_to_ragged_batch\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\data\\experimental\\service\\__init__.py:419\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;124;03m\"\"\"API for using the tf.data service.\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \n\u001B[0;32m     17\u001B[0m \u001B[38;5;124;03mThis module contains:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    416\u001B[0m \u001B[38;5;124;03m  job of ParameterServerStrategy).\u001B[39;00m\n\u001B[0;32m    417\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m--> 419\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata_service_ops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m distribute\n\u001B[0;32m    420\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata_service_ops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m from_dataset_id\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\data_service_ops.py:26\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mservice\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _pywrap_utils_exp\n\u001B[1;32m---> 26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dataset_ops\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m options \u001B[38;5;28;01mas\u001B[39;00m options_lib\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:34\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m debug_mode\n\u001B[1;32m---> 34\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m iterator_ops\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m options \u001B[38;5;28;01mas\u001B[39;00m options_lib\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:45\u001B[0m\n\u001B[0;32m     44\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtrackable\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m base \u001B[38;5;28;01mas\u001B[39;00m trackable\n\u001B[1;32m---> 45\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtraining\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaver\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BaseSaverBuilder\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m deprecation\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\training\\saver.py:50\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtrackable\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m base \u001B[38;5;28;01mas\u001B[39;00m trackable\n\u001B[1;32m---> 50\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtraining\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m py_checkpoint_reader\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtraining\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m training_util\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py:19\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m compat\n\u001B[1;32m---> 19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pywrap_checkpoint_reader\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CheckpointReader\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtf_export\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tf_export\n",
      "\u001B[1;31mSystemError\u001B[0m: initialization of _pywrap_checkpoint_reader raised unreported exception",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01melasticsearch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Elasticsearch\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pipeline\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mrequests\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Initialize Elasticsearch (ensure Elasticsearch is running locally or on your specified URL)\u001B[39;00m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1231\u001B[0m, in \u001B[0;36m_handle_fromlist\u001B[1;34m(module, fromlist, import_, recursive)\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\import_utils.py:1136\u001B[0m, in \u001B[0;36m_LazyModule.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1134\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_module(name)\n\u001B[0;32m   1135\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_class_to_module\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m-> 1136\u001B[0m     module \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_class_to_module\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1137\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(module, name)\n\u001B[0;32m   1138\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\import_utils.py:1148\u001B[0m, in \u001B[0;36m_LazyModule._get_module\u001B[1;34m(self, module_name)\u001B[0m\n\u001B[0;32m   1146\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m importlib\u001B[38;5;241m.\u001B[39mimport_module(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m module_name, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[0;32m   1147\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m-> 1148\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m   1149\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to import \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodule_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m because of the following error (look up to see its\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1150\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m traceback):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1151\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Failed to import transformers.pipelines because of the following error (look up to see its traceback):\ninitialization of _pywrap_checkpoint_reader raised unreported exception"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from transformers import pipeline\n",
    "import requests\n",
    "\n",
    "# Initialize Elasticsearch (ensure Elasticsearch is running locally or on your specified URL)\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "index_name = \"research_papers\"\n",
    "\n",
    "# Initialize Hugging Face models for summarization and Q&A\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "qa_model = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
    "\n",
    "# Define a function to create the Elasticsearch index\n",
    "def initialize_index():\n",
    "    mapping = {\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"title\": {\"type\": \"text\"},\n",
    "                \"abstract\": {\"type\": \"text\"},\n",
    "                \"published_date\": {\"type\": \"date\"},\n",
    "                \"authors\": {\"type\": \"text\"},\n",
    "                \"pdf_url\": {\"type\": \"keyword\"}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    if not es.indices.exists(index=index_name):\n",
    "        es.indices.create(index=index_name, body=mapping)\n",
    "        print(f\"Index '{index_name}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Index '{index_name}' already exists.\")\n",
    "\n",
    "initialize_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780d6714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
